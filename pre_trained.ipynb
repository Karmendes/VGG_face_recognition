{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "liveness",
   "display_name": "liveness"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from scipy.spatial.distance import cosine\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from pre_process import pre_process_frame\n",
    "from collections import Counter \n",
    "from imutils import paths\n",
    "from pandas import DataFrame\n",
    "import cv2\n",
    "import glob\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Model\n",
    "vggface = VGGFace(model='senet50',include_top=False, input_shape=(224, 224, 3))\n",
    "detector = cv2.CascadeClassifier('detector.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils functions\n",
    "\n",
    "def extract_face(filename,detector,required_size=(224, 224)):\n",
    "    pixels = cv2.imread(filename)\n",
    "    results = pre_process_frame(pixels,detector)\n",
    "    if len(results) > 0:\n",
    "        x1, y1, width, height = results\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = asarray(image)\n",
    "        return face_array\n",
    "    else:\n",
    "        return []\n",
    "def get_embeddings(filenames,detector):\n",
    "    faces = []\n",
    "    nomes = []\n",
    "    for f in filenames:\n",
    "        result = extract_face(f,detector)\n",
    "        if len(result) > 0:\n",
    "            nomes.append(f.split(os.path.sep)[-2])\n",
    "            faces.append(result)\n",
    "    samples = asarray(faces,'float32')\n",
    "    samples = preprocess_input(samples, version=2)\n",
    "    yhat = vggface.predict(samples)\n",
    "    return yhat,nomes\n",
    "def most_frequent(List): \n",
    "    occurence_count = Counter(List) \n",
    "    return occurence_count.most_common(1)[0][0] \n",
    "# determine if a candidate face is a match for a known face\n",
    "def is_match(known_embedding, candidate_embedding, thresh=0.5):\n",
    "\t# calculate distance between embeddings\n",
    "\tscore = cosine(known_embedding, candidate_embedding)\n",
    "\tif score <= thresh:\n",
    "\t\tprint('>face is a Match (%.3f <= %.3f)' % (score, thresh))\n",
    "\telse:\n",
    "\t\tprint('>face is NOT a Match (%.3f > %.3f)' % (score, thresh))\n",
    "def get_name(known_embedding, candidate_embedding,names_collections, thresh=0.5):\n",
    "    candidates = []\n",
    "    for embedding,name in zip(known_embedding,names_collections):\n",
    "        score = cosine(candidate_embedding, embedding)\n",
    "        if score <= thresh:\n",
    "            candidates.append(name)\n",
    "    if len(candidates) > 0:\n",
    "        name = most_frequent(candidates)\n",
    "    else:\n",
    "        name = 'Unknown'\n",
    "    return name\n",
    "def get_name_mean(known_embedding, candidate_embedding,names_collections,threshold = 0.5):\n",
    "    distance = []\n",
    "    candidate = []\n",
    "    for embedding,name in zip(known_embedding,names_collections):\n",
    "        score = cosine(candidate_embedding, embedding)\n",
    "        distance.append(score)\n",
    "        candidate.append(name)\n",
    "    dic = {\n",
    "            'Distance':distance,\n",
    "            'candidate':candidate\n",
    "    }\n",
    "    df = DataFrame(dic)\n",
    "    df_mean = df.groupby(['candidate'])['Distance'].agg(['mean']).reset_index()\n",
    "    minimo = df_mean['mean'].min()\n",
    "    row_min = df_mean[df_mean['mean'] == minimo]\n",
    "    min_dist = row_min.mean().to_list()[0]\n",
    "    name = row_min.candidate.to_list()[0]\n",
    "    # give name\n",
    "    if min_dist < threshold:\n",
    "        return name\n",
    "    else:\n",
    "        return 'Unknown'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x84f013c80> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: 'arguments' object has no attribute 'posonlyargs'\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x84f013c80> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: 'arguments' object has no attribute 'posonlyargs'\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
    }
   ],
   "source": [
    "# Testing with everyone\n",
    "database,names = get_embeddings(list(paths.list_images(\"Test/\")),detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test personal\n",
    "entrance,names_entrance = get_embeddings(list(paths.list_images(\"Train/\")),detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for election\n",
    "data = {\n",
    "    'name':[],\n",
    "    'predict':[],\n",
    "    'threshold':[]\n",
    "}\n",
    "for threshold in range(10,70):\n",
    "    for embedding,nome in zip(entrance,names_entrance):\n",
    "        predict = get_name(database,embedding,names,(threshold/100))\n",
    "        data['name'].append(nome)\n",
    "        data['predict'].append(predict)\n",
    "        data['threshold'].append((threshold/100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mean\n",
    "data_mean = {\n",
    "    'name':[],\n",
    "    'predict':[],\n",
    "    'threshold':[]\n",
    "}\n",
    "for threshold in range(10,70):\n",
    "    for embedding,nome in zip(entrance,names_entrance):\n",
    "        predict = get_name_mean(database,embedding,names,(threshold/100))\n",
    "        data_mean['name'].append(nome)\n",
    "        data_mean['predict'].append(predict)\n",
    "        data_mean['threshold'].append((threshold/100))"
   ]
  }
 ]
}